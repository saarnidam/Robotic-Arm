{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d217143",
   "metadata": {},
   "source": [
    "# clanker robot arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d9cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import serial\n",
    "import time\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f7d6c",
   "metadata": {},
   "source": [
    "### constants initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a5619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERIAL_PORT = 'COM3'\n",
    "BAUD_RATE = 115200\n",
    "CAMERA_INDEX = 0\n",
    "SMOOTHING_WINDOW = 7 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e12c77-a3d2-475b-bb2b-039e8811e168",
   "metadata": {},
   "source": [
    "### This creates the serial comms channel between python and arduino through CVzone library and has code that accounts for error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b58372-a5ef-4c78-be09-ef251aabc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    arduino = serial.Serial(SERIAL_PORT, BAUD_RATE, timeout=1)\n",
    "    time.sleep(2)\n",
    "    print(f\"✓ Arduino connected on {SERIAL_PORT}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Arduino error: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "#CVZone hand detector\n",
    "detector = HandDetector(detectionCon=0.7, maxHands=1)\n",
    "\n",
    "#webcam\n",
    "cap = cv2.VideoCapture(CAMERA_INDEX)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"✗ Webcam error\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2099bb6f-d600-4d1f-81a0-e6db60280eda",
   "metadata": {},
   "source": [
    "#### Mapping out the landmarks over the hand, in relation to the computer vision. this code measures the bending of each finger. \n",
    "Index → Servo A\n",
    "\n",
    "Middle → Servo D\n",
    "\n",
    "Ring → Servo B\n",
    "\n",
    "Pinky → Servo C\n",
    "\n",
    "Thumb → Servo E \n",
    "\n",
    "this organises each finger based on the servo motor its connected to. additionaly i added a buffer that helps remove jitter and make sure there isnt random servo motor vibration\n",
    "\n",
    "then with the finger id part of the code, using math to measure from the base knuckle to the finger (4 landmarks for each finger)\n",
    "\n",
    "dist = sqrt((x2-x1)² + (y2-y1)²) this specific calculation determines a large or short distance ( corresponding to open or bent finger)\n",
    "\n",
    "at the end def send_to_arduino(bend_dict): will send the data over to the arduino in this format A,B,C,D,E\\n\n",
    "\n",
    "i also added error handling to prevent a crash if the arduino disconnects or smthn like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b86267c-d1fc-4f89-a36d-83ff50bd533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finger Mapping (NOW WITH THUMB)\n",
    "FINGERS = {\n",
    "    'thumb': 0,\n",
    "    'index': 1,\n",
    "    'middle': 2,\n",
    "    'ring': 3,\n",
    "    'pinky': 4\n",
    "}\n",
    "\n",
    "SERVO_MAP = {\n",
    "    'index': 'A',\n",
    "    'middle': 'D',\n",
    "    'ring': 'B',\n",
    "    'pinky': 'C',\n",
    "    'thumb': 'E'  \n",
    "}\n",
    "\n",
    "# Calibration\n",
    "calib_state = 'collecting_open'\n",
    "calib_frames_needed = 60\n",
    "calib_frame_count = 0\n",
    "\n",
    "calib_data = {\n",
    "    'thumb': {'open_samples': [], 'closed_samples': [], 'open': None, 'closed': None},\n",
    "    'index': {'open_samples': [], 'closed_samples': [], 'open': None, 'closed': None},\n",
    "    'middle': {'open_samples': [], 'closed_samples': [], 'open': None, 'closed': None},\n",
    "    'ring': {'open_samples': [], 'closed_samples': [], 'open': None, 'closed': None},\n",
    "    'pinky': {'open_samples': [], 'closed_samples': [], 'open': None, 'closed': None}\n",
    "}\n",
    "\n",
    "smooth_buffers = {f: deque(maxlen=SMOOTHING_WINDOW) for f in FINGERS.keys()}\n",
    "\n",
    "\n",
    "def get_finger_distance(lmList, finger_name):\n",
    "    \"\"\"Get distance from fingertip to base\"\"\"\n",
    "    finger_id = FINGERS[finger_name]\n",
    "    \n",
    "    # CVZone landmarks\n",
    "    base_idx = finger_id * 4 + 1\n",
    "    tip_idx = finger_id * 4 + 4\n",
    "    \n",
    "    if len(lmList) > tip_idx:\n",
    "        base = lmList[base_idx]\n",
    "        tip = lmList[tip_idx]\n",
    "        \n",
    "        dist = np.sqrt((tip[0] - base[0])**2 + (tip[1] - base[1])**2)\n",
    "        return dist\n",
    "    return 0\n",
    "\n",
    "def normalize_bend(dist, open_dist, closed_dist):\n",
    "    if open_dist == closed_dist:\n",
    "        return 0.0\n",
    "    norm = (open_dist - dist) / (open_dist - closed_dist)\n",
    "    return np.clip(norm, 0.0, 1.0)\n",
    "\n",
    "def smooth_value(finger, value):\n",
    "    smooth_buffers[finger].append(value)\n",
    "    return sum(smooth_buffers[finger]) / len(smooth_buffers[finger])\n",
    "\n",
    "def send_to_arduino(bend_dict):\n",
    "    # Format: \"bendA,bendB,bendC,bendD,bendE\\n\"\n",
    "    servo_values = {\n",
    "        'A': bend_dict.get('index', 0.0),\n",
    "        'B': bend_dict.get('ring', 0.0),\n",
    "        'C': bend_dict.get('pinky', 0.0),\n",
    "        'D': bend_dict.get('middle', 0.0),\n",
    "        'E': bend_dict.get('thumb', 0.0)  # NEW\n",
    "    }\n",
    "    cmd = f\"{servo_values['A']:.3f},{servo_values['B']:.3f},{servo_values['C']:.3f},{servo_values['D']:.3f},{servo_values['E']:.3f}\\n\"\n",
    "    try:\n",
    "        arduino.write(cmd.encode())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e3d155-b3f7-4098-9f2e-5b7ee5be1d1b",
   "metadata": {},
   "source": [
    "### Over here i created a little dashboard to show the calibration status and the finger bends in real time. in the calibration it requires user to hold hand open and closed for a couple of seconds before they can begin\n",
    " this code if key == 'thumb':\n",
    "    pwm = 1200 + int(bend * 600)\n",
    "else:\n",
    "    pwm = 500 + int(bend * 2000) converts the bend into PWM which is what the arduino outputs \n",
    "\n",
    "\n",
    "hands, frame = detector.findHands(frame, draw=True, flipType=False)\n",
    "\n",
    "this crucial part is what actually detects the hand landmarks through mediapipe (hands is what has the landmark data that for logic)\n",
    "\n",
    "\n",
    "with a quick function  this creates the bend bars that show in real time the bending of each finger\n",
    "\n",
    "fill = int(bend * bar_w)\n",
    "cv2.rectangle(...) \n",
    "\n",
    "and lastly i added user controls like R for recalibration and Q to quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be66a82-78b7-42a2-a996-759d0d779349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_ui(frame, bend_dict, calib_state, calib_progress, hand_detected, fps):\n",
    "    h, w = frame.shape[:2]\n",
    "    \n",
    "    overlay = frame.copy()\n",
    "    cv2.rectangle(overlay, (0, 0), (w, 270), (25, 25, 25), -1)  # Taller for 5 fingers\n",
    "    cv2.addWeighted(overlay, 0.85, frame, 0.15, 0, frame)\n",
    "    \n",
    "    cv2.putText(frame, \"ROBOTIC HAND (5 FINGERS)\", (20, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 255), 2)\n",
    "    \n",
    "    cv2.putText(frame, f\"FPS: {fps:.0f}\", (w-130, 40),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "    \n",
    "    if calib_state == 'collecting_open':\n",
    "        status = f\"HOLD OPEN HAND... {calib_progress}%\"\n",
    "        color = (0, 165, 255)\n",
    "    elif calib_state == 'collecting_closed':\n",
    "        status = f\"HOLD CLOSED FIST... {calib_progress}%\"\n",
    "        color = (0, 165, 255)\n",
    "    else:\n",
    "        status = \"CALIBRATED - CONTROLLING ROBOT\"\n",
    "        color = (0, 255, 0) if hand_detected else (0, 0, 255)\n",
    "    \n",
    "    cv2.putText(frame, status, (20, 80),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "    \n",
    "    if calib_state != 'calibrated':\n",
    "        bar_x, bar_y = 20, 100\n",
    "        bar_w, bar_h = 400, 20\n",
    "        cv2.rectangle(frame, (bar_x, bar_y), (bar_x+bar_w, bar_y+bar_h), (60,60,60), -1)\n",
    "        fill = int((calib_progress/100) * bar_w)\n",
    "        cv2.rectangle(frame, (bar_x, bar_y), (bar_x+fill, bar_y+bar_h), (0,255,255), -1)\n",
    "        cv2.rectangle(frame, (bar_x, bar_y), (bar_x+bar_w, bar_y+bar_h), (255,255,255), 2)\n",
    "    \n",
    "    if calib_state == 'calibrated':\n",
    "        y = 120\n",
    "        fingers_display = [\n",
    "            ('Thumb (E→D8)',  'thumb',  (255, 150, 50)),   # NEW\n",
    "            ('Index (A→D3)',  'index',  (100, 200, 255)),\n",
    "            ('Middle (D→D9)', 'middle', (100, 255, 100)),\n",
    "            ('Ring (B→D5)',   'ring',   (255, 200, 100)),\n",
    "            ('Pinky (C→D6)',  'pinky',  (255, 100, 200))\n",
    "        ]\n",
    "        \n",
    "        for label, key, color in fingers_display:\n",
    "            bend = bend_dict.get(key, 0.0)\n",
    "            \n",
    "            # Thumb uses different range\n",
    "            if key == 'thumb':\n",
    "                pwm = 1200 + int(bend * 600)  # 1200-1800 for MG90\n",
    "            else:\n",
    "                pwm = 500 + int(bend * 2000)   # 500-2500 for MG996R\n",
    "            \n",
    "            text = f\"{label}: {bend:.2f} → {pwm}µs\"\n",
    "            cv2.putText(frame, text, (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,255,255), 1)\n",
    "            \n",
    "            bar_x = 350\n",
    "            bar_w = 300\n",
    "            bar_h = 16\n",
    "            cv2.rectangle(frame, (bar_x, y-13), (bar_x+bar_w, y-13+bar_h), (60,60,60), -1)\n",
    "            fill = int(bend * bar_w)\n",
    "            cv2.rectangle(frame, (bar_x, y-13), (bar_x+fill, y-13+bar_h), color, -1)\n",
    "            cv2.rectangle(frame, (bar_x, y-13), (bar_x+bar_w, y-13+bar_h), (255,255,255), 2)\n",
    "            \n",
    "            y += 26\n",
    "    \n",
    "    cv2.putText(frame, \"Q: Quit  |  R: Recalibrate\", (20, h-20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (180,180,180), 1)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Main Loop\n",
    "frame_count = 0\n",
    "fps = 0\n",
    "fps_time = time.time()\n",
    "\n",
    "print(\"✓ Starting...\\n\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    hands, frame = detector.findHands(frame, draw=True, flipType=False)\n",
    "    \n",
    "    bend_values = {}\n",
    "    hand_detected = False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e0b5cf-3cba-41b3-aa27-f46527e21718",
   "metadata": {},
   "source": [
    "### This final chunk of code is a continuation to the markdown before which controls calibration and smoothens values from the live bend of the finger through the land mark tracking\n",
    "\n",
    "the 'if hands:' conditional only runs the tracking if there is a detected hand within the webcam \n",
    "\n",
    "for fname in FINGERS.keys():\n",
    "    calib_data[fname]['closed'] = np.mean(calib_data[fname]['closed_samples'])\n",
    "calib_state = 'calibrated'\n",
    "print(\"✓ Calibrated! Controlling 5 fingers...\\n\")\n",
    "\n",
    "this is the code for the finishe calibration of the closed hand. which shows visually the arm is fully calibrated and begins hand control. \n",
    "\n",
    "each finger frame: \n",
    "\n",
    "dist = get_finger_distance(lmList, fname)\n",
    "open_d = calib_data[fname]['open']\n",
    "closed_d = calib_data[fname]['closed']\n",
    "\n",
    "if open_d and closed_d:\n",
    "    bend = normalize_bend(dist, open_d, closed_d)\n",
    "    smooth = smooth_value(fname, bend)\n",
    "    bend_values[fname] = smooth\n",
    "\n",
    "this code runs a pipeline that measures the current finger distance, fetches that finger’s calibrated open/closed distances and convert to bend [0,1] or in other words open or closed and stores the result in bend_values\n",
    "\n",
    "this is lastly then sent to arduino through this code send_to_arduino(bend_values)\n",
    "\n",
    "i later decided to add this conditional \n",
    "\n",
    "if frame_count % 2 == 0:\n",
    "\n",
    "that sends the data to arduino every 2 frames so i could reduce serial bandwith usage\n",
    "\n",
    "and after just some final code and controls to quit the software and drawing the user interface\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7896cb-7431-4723-a9df-e84d2587f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hands:\n",
    "        hand_detected = True\n",
    "        hand = hands[0]\n",
    "        lmList = hand['lmList']\n",
    "        \n",
    "        if calib_state in ['collecting_open', 'collecting_closed']:\n",
    "            for fname in FINGERS.keys():\n",
    "                dist = get_finger_distance(lmList, fname)\n",
    "                \n",
    "                if calib_state == 'collecting_open':\n",
    "                    calib_data[fname]['open_samples'].append(dist)\n",
    "                else:\n",
    "                    calib_data[fname]['closed_samples'].append(dist)\n",
    "            \n",
    "            calib_frame_count += 1\n",
    "            \n",
    "            if calib_frame_count >= calib_frames_needed:\n",
    "                if calib_state == 'collecting_open':\n",
    "                    for fname in FINGERS.keys():\n",
    "                        calib_data[fname]['open'] = np.mean(calib_data[fname]['open_samples'])\n",
    "                    calib_state = 'collecting_closed'\n",
    "                    calib_frame_count = 0\n",
    "                    print(\"✓ Open calibrated! Close fist...\")\n",
    "                \n",
    "                elif calib_state == 'collecting_closed':\n",
    "                    for fname in FINGERS.keys():\n",
    "                        calib_data[fname]['closed'] = np.mean(calib_data[fname]['closed_samples'])\n",
    "                    calib_state = 'calibrated'\n",
    "                    print(\"✓ Calibrated! Controlling 5 fingers...\\n\")\n",
    "        \n",
    "        elif calib_state == 'calibrated':\n",
    "            for fname in FINGERS.keys():\n",
    "                dist = get_finger_distance(lmList, fname)\n",
    "                open_d = calib_data[fname]['open']\n",
    "                closed_d = calib_data[fname]['closed']\n",
    "                \n",
    "                if open_d and closed_d:\n",
    "                    bend = normalize_bend(dist, open_d, closed_d)\n",
    "                    smooth = smooth_value(fname, bend)\n",
    "                    bend_values[fname] = smooth\n",
    "            \n",
    "            if frame_count % 2 == 0:\n",
    "                send_to_arduino(bend_values)\n",
    "    \n",
    "    if calib_state in ['collecting_open', 'collecting_closed']:\n",
    "        progress = int((calib_frame_count / calib_frames_needed) * 100)\n",
    "    else:\n",
    "        progress = 100\n",
    "    \n",
    "    if frame_count % 10 == 0:\n",
    "        now = time.time()\n",
    "        fps = 10.0 / (now - fps_time)\n",
    "        fps_time = now\n",
    "    \n",
    "    frame = draw_ui(frame, bend_values, calib_state, progress, hand_detected, fps)\n",
    "    \n",
    "    frame_count += 1\n",
    "    cv2.imshow('Robotic Hand Control', frame)\n",
    "    \n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):\n",
    "        calib_state = 'collecting_open'\n",
    "        calib_frame_count = 0\n",
    "        for fname in FINGERS.keys():\n",
    "            calib_data[fname] = {'open_samples': [], 'closed_samples': [], 'open': None, 'closed': None}\n",
    "            smooth_buffers[fname].clear()\n",
    "        print(\"\\n✓ Recalibrating...\")\n",
    "\n",
    "# Cleanup\n",
    "print(\"\\n✓ Shutting down...\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "arduino.close()\n",
    "print(\"✓ Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063db9c0-8937-4eba-9af6-2e75e9e49a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
